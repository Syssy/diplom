 
5.5.

Lesen: PAAs, qqPlots ok

Angucken: Heatmaps bzw Kurven

Offen:  T = T1+...+TN mit N zufällig?, was war damit genau gemeint? -> N zufällig anhand der beiden (1, 2, 3 je nachdem) Parameter bestimmen?

Testen: qqPlots ok, jetzt: Ergebnisse des Testprogrammierens gegen InvGauß qqplotten

Brauche: Kurven zum Vergleichen


14.5.
* Physikalische Größen recherchieren (Länge/Durchmesser der MCC, Teilchengröße, Geschwindigkeit, Wechsel zwischen Phasen, Sorption (Kurve?), wie viele Teilchen nebeneinander)
* Gesamtziel: Modelle entwickeln. Verschiedene Möglichkeiten: Ganz einfach mit nur 1 Parameter u 1 Teilchen gleichzeitig, oder zwei Param. 2/3Phasen? Mehrere Teilchen gleichzeitig (wegen Sorption und alle Plätze voll, also Teilchen abhängig voneinander) Wartezeit zu Beginn (->Phys? Wie viele Teilchen/% auf einmal). Konst. Geschwindigkeit (amortisiert sich das nicht über die Länge der MCC?)
* Bis nächste Woche: Modelle sortieren/überlegen, welche es gibt, phys größen

* Formalkram: Expose: Zur Anmeldung nötig, zwei Seiten
* Formalkram: Einführungsvortrag ca 1 Monat nach Anmeldung (Termin rechtzeitig wegen 2. Prüfer)

* Was ergibt sich bei nicht gleichverteilten Zufallszahlen (fürs Hängenbleiben/Lösen) sondern nach anderer Verteilung, macht das Sinn? Oder kann man den Effekt auch erzielen, wenn man eher an den Nachkommastellen von p spielt?


27.5.
* Möglichkeit, die Sim (Counter) zu speichern, um nachträglich noch mehrere Vergleiche anstellen zu können, dabei verwendete Parameter etc. mitspeichern (ok) -> fromfile, tofile, dazu header, wo anzahl etc drin sind


05.06.
* 10000 zz auf ein mal ziehen -> beschleunigen ?!? ok
* kann man bei der hängenbleib-entscheidung was beschleunigen? ok
* Ausgabe der fit-Parameter ok

11.06. 
* Expose anfangen!
* GUI?
* IDE??
* Ausgabe der Stat: Beliebig viele Sim *ok*, bzw. anhand von header-config auswählen hä?
* Gedanken zu meinen files: csv kann man zwar schön lesen, braucht man aber eig. nicht. 
  Vorschlag: Erstelle class wo die Parameter und Zeiten drin sind, das kann ich dann picklen, plotkram kann das dann auch einlesen ok
  Muss noch ein Paket für die Sim erstellen ok
* argparse
* InvGauß: Gucken, was genau mu, loc, scale an den kurven verändern. evtl viele Plot zum vergleich (ok)
* Viele ps/pm Kombis ausprobieren und testen, was da sinnvoll ist. Ausgabe??? 
* Erstelle Liste für WKeiten und ziehe vier paare zufällig, gucken, was das so rauskommt ok 


01.07.2014
* Expose! Evtl mal Felix/Nina fragen ok
* Nach echten Messungen fragen, angucken -> Dommi
* Option für nur plot (-> argparse)
* Sicherung! (git etc)
* Startparameter für fit-Funktion? nö
* GUI: verschoben
 ** Parameter einstellen (Slider)
 ** Speicheroption
 ** Zoom/Achsenbeschriftung für Spektren

 * Schiefe angucken
 -> Heatmaps für Erwartungswerte, Varianzen, Schiefen der Simulationen (für interessante Werte; Ecken, 100 Punkte an je beiden Enden)
 * Erstelle erst Matrix für die Momente, mit leeren Einträgen an den nicht interessanten Stellen. Muss die dann über die params an den geeigneten Stellen wieder füllen. 

*** WICHTIG ***
 Beim Starten größerer Durchgänge unbedingt aktuelles Progamm sichern, sonst nix mehr nachvollziehbar!!!
 Abhängigkeiten sind nicht gut (statsmodels) da es auch auf den Uni-rechnern laufen muss
 
* Wie kann man mehrere eigene Pakete mit Abhängigkeiten "installieren" 
* argparse, damit man den Plotkram auch mit alten Dateien starten kann (teilweise ok)

* Erstelle für die Heatmaps vier subplots für die Ecken, da sonst Werte zu unterschiedlich für schöne plots, plus gemeinsamen Plot ok
* Reihenfolge der pms, pss sollte doch gleich sein, sonst blick ich nicht mehr durch -> egal, wird jetzt sortiert

31.7.
* skewness und kurtosis neu berechnen?!  An der Uni das recalc testen!! Kann ja wohl nicht sein, dass das so unterschiedlich ist. Liegt auf jeden Fall am fit. An der Uni scipy 0.9.0, am Laptop 0.13.3
* Mail wegen batchsystem ok
* Nach Params sortieren und dann plotten, (ok)
* plotkram (4heats) mit kleinerer anzahl sims testen, damit man auch sieht, ob es läuft ok
* Beim Testen, ob Sim schon vorhanden, diese auch in Liste packen, damit am Ende was vollständiges abgespeichert wird! ok
* Wo müssen bei methoden von klassen die selfs dazu?
* Statt erst die Params für die InvGauß direkt die Momente berechnen!! (-> Wie geht das? Scipy kann das!) ok

05.08.2014
* Momente direkt berechnen (ok)
* sim auf snail laufen lassen!! (läuft) Dabei Test, ob Ergebnisse schon vorliegen auf length und count erweitern, Sims davon in Liste (ok)
* Expose
* 4heats hübsch machen joa
* 4 heats mit ein heat kombi ok
* Kommentieren!!!
* Aus großer Menge *.p passende Sims raussuchen und plotten (Param-liste mit kombi von zahl und länge, ähnlich wie bei sim)
* Simulationsklasse vernünftig in plotkram einbinden
* Warum zur Hölle sind plötzlich die Plots nicht mehr richtig sortiert??? (Liegt an der anderen Sortierung der .pickle's als der .p's. Achsenbeschriftung ist auch irreführend) ok
* Vorbereitung auf Treffen: Einzelne Plots angucken ok
* Option für recalc, irgendwie das recalc auch abspeichern (ok -> in plotkram, die Option rc)
* Für Fakesims mean/variance nicht = 0 damit das mit dem log-Plotten klappt

nächstes Treffen 4.9. 16 Uhr

-m cProfile  -o sim.prof  sim.py ->  gucken, wo ich die meiste Zeit brauche

Aufschreiben: 2 Params scheinen nicht zu reichen -> Done
Geschwindigkeitsparameter.
Wie oft bleiben die teile hängen. sim: auswürfeln, wann wieder was passiert, statt jeden zeitpunkt zu betrachten ? (Lohnt das? -> cProfile)
Dommi nach Daten fragen (spektrum mit guten params und wenigen Peaks) ok
Simulation einer Multikapillarsäule bei der Ionenmobilitätspektrometrie

14.08.2014
* Dommis File angucken, antworten (ok), vor allem noch mal ne einzelne Zeitspalte angucken, evtl. schauen, was scipys fit damit macht, qq-Plot (ok, aber hier bin ich noch nicht fertig)
* Testen besser machen (zu viele unübersichtliche ifs ob schon vorhanden) ok?
* Aufräumen: Universionen mit dem hier synchronisieren. Unterordner für Länge und Anzahl, .pickles nach parameterbereichen benennen ok
* Expose (bin dran...)
* Einzelne Sims samt Histogram, fit-Plot und qq abspeichern und gut kommentieren

* testen: pm>ps sollte für schmalere peaks sorgen, daher das mit langsamerer vel kombinieren

* Was passiert wann - Simulation: Auswürfeln, wann wieder was passiert, statt jeden Zeitpunkt: 
 ** Wie bestimme ich den nächsten Zeitpunkt? Erst mal gleichverteilt, um zu gucken, ob das überhaupt sinn ergibt s.u.
 ** Wo speichere ich den ganzen Kram ab? Kann ich dafür auch np-arrays nutzen oder muss ich das einzeln machen?
 ** Mache Liste für jeden Zeitpunkt, wo alle relevanten Teilchen drin sind.
 ** Pro Teilchen speichere Ort und Zustand (Geschw... etc)
 ** Teste auf fertig? -> bei jeweils jedem Schritt 
 ** Wie würfele ich den nächsten Zeitpunkt richtig aus? (Also Params einbauen!) ok
 ** Ergebnisse plotten
 ** Verteilung für nächsten Zeitpunkt? -> Geometrisch (bestätigt)
 ** KOMMENTIEREN ok
 ** Profiling davon
 
04.09.2014
 * Dommis File: Plotten ohne Histogramm, sondern Punkte verbinden
 * p = 1/v * gamma; pm=ps? Damit es nicht noch mehr Params werden -> Ausprobieren
 * Dummerweise hab ich nicht mehr so ganz in Erinnerung, was genau beim 4.9. gesagt wurde :( Ich sollte nur das mit den Geschwindigkeiten weiter ausprobieren und rausfinden, ob das ein guter Ansatz ist.
 * Finde sinnvolle Werte für v und gamma, sodass p immer noch nahe 1 ist
 * Außerdem soll v sich ändern können, insbes. nach Wechselwirkung
 * Evtl in die wpw einbaubar: in der sim brauche ich nur einen param, anhand dessen bestimmt wird, wann wieder was passiert und halt die vel, die mir sagt, wie weit ich gehe. Das evtl. neu-setzen des params dann in extra methode? Nee, hier nicht einbaubar, da Geschwindigkeitsänderungen... Oder doch, wenn man einfach die Durchschnittgeschwindigkeit über den Zeitraum annimmt?
 * Interessant wären durschnittswerter für vel und p 
 * Zusammenhänge zwischen den Params herausfinden, welche Kombis sind sinnvoll? Effekte der einzelnen auf die Sim?
 
 29.09.2014
 * Sim002 mit Wechselw'keit anfangen
 * Gedankenspiel... Gehe noch mal zurück zu den Modellen 1a/b: In b ist p die W'keit im nächsten Schritt mobil zu sein. Also immer gleich, unabhängig vom aktuellen Zustand. Dadurch gibt es aber schon im Ansatz den gewünschten Effekt: Je größer p, desto weiter vorne und schmaler ist der Peak.(Allerdings kein verstärktes Tailing bei den hinteren Peaks, nur insgesamt flacher)
 Außerdem widerspricht das der aktuellen Überlegung, dass die W'keit geschwindigkeitsabhängig ist. Neuer Gedankengang... 
 Die W'keit mobil zu sein, hängt nur von der aktuellen Geschwindigkeit ab (mit irgendeinem Faktor). Bin ich normal-schnell gibt es halt eine gewisse Wkeit hängen zu bleiben. Bin ich schneller, ist diese geringer. Wenn ich schon hänge, ist sie sehr groß (weiter hängen bleiben realistisch)
 
 * Achtung: Länge der Säule anpassen an Geschwindigkeit, sonst bekomme ich wieder den führungspeak. Außerdem sinnvolle Werte für den veldivisor mit einbeziehen, da das die maximal (tatsächlich) erreichte vel doch sehr verändert
 * Vom Gefühl her ist es besser, ps weiter als (festen) Parameter zu haben.
 * Berechnung der neuen Geschwindigkeit muss evtl noch angepasst werden. Keine Ahnung, was da realistisch ist. Bisher wird einfach der veldivisorste Teil der Differenz zwischen aktueller und maximaler Geschwindigkeit genommen. Dadurch werden langsame Teilchen mehr beschleunigt, als schnelle. Vielleicht ergibt aber auch was anderes mehr Sinn.
 * Es gibt grad so viel auszuprobieren... Das ist auch gut, aber bitte dokumentieren. Oder wenigstens die Bilder abspeichern... (ok)
 * Gleiches für die älteren Versionen, dann hab ich schon mal was fürs zusammenschreiben
 * Versuche Wissen von Figure1 zu nutzen...
 * Warum habe ich die Idee, ps auch von gamma abhängig zu machen verworfen? Da vielleicht noch mal Gedanken zu machen
 * Es sollte geklärt werden, was an festen Parametern sinnvoll ist. Also velmin/max und evtl. ps. Das scheint im Moment recht willkürlich zu sein.
 * Es wäre hübsch, wenn die Geschwindigkeit zb Normalverteilt wäre (also Kurve mit Maximum) und nicht hauptsächlich an den Rändern. Dann könnte man durch geschickte Parameterwahl dieses Maximum hin und her schieben. -> Noch mal bei Figure1 gucken, da war die zweite Kurve ja im Ansatz so, vielleicht bekommt man das mit nem anderen maximalwert ja hin? So spontan eher nicht. 
 Sollte das nicht gerade durch das ganze Hängen-bleiben erreicht werden? Tut es ja auch, aber leider wird die Varianz dabei zu groß
 * Fronting bei Figure1 zu klären? Gab es das da? Ist ja auch ein Effekt von hohem ps
 
 * EXPOSE: Hätte gerne irgendwelche Bilder, an denen man das mit dem Tailing und der Varianz gut sehen kann
 * EXPOSE: Noch mal Literatur raussuchen, evtl querlesen. V.a. was zur MCC/ GC
 
 * Kann man die Geschwindigkeit einfach weglassen und nur mit variablen Wahrscheinlichkeiten arbeiten? Müsste im Endeffekt auf's gleiche rauskommen, aber man könnte zwei Parameter weglassen) Das könnte vor allem bei der wpw-Sim einbaubar sein
 
10.10.2014
* Echte Daten raussuchen, Einheiten festlegen: Zeitschritt = 1/1000s (oder später 1/10000) Messung nur alle 1/10s (real). Geschwindigkeit raussuchen
 (40cm/s bei 30-60s pro Messung und 4-25cm Länge) In der Besprechung war von ca 10min pro Messung die Rede, wie passt das denn nu?
* Mit dem 2-Param-Modell noch mal einige Param-Kombis testen und gucken, wie man die Peaks so schmal bekommt
* Breite des Peaks bei halbem Maximalwert; Gucken, wie das mit steigender Zeit ist. (Verhältnis Peakmax zu 1/2Peakmax) Dazu:Dommi anschreiben ok
* Dann gucken, bei welchen p/q (pm/ps)-Kombis das hinkommt (plotten), evtl könnte man da eine Funktion für finden
* PAA-Ansatz, die Formel angucken und gucken, wie sich das berechnen lässt. Eigentlich ja "nur" ne einfache Rekursion, muss nur sehr auf den Speicher achten

* Den Berechnungsansatz kommentieren!!

* Aus dem Gespräch mit Dommi:
 ** Die Breite bei halbem Maxwert hat er nur für IMS-Messungen, da gibt es ne Berechnung, die Faktoren der IMS wie Gitteröffnungzeit mit einbezieht, das kann man nicht einfach so auf die MCC übertragen. Da scheint die Breite unabhängig zb von der Injektionszeit zu sein
 ** Um die Peaks der MCC zu bekommen, müsste ich von den Spektren den RIP rausrechnen, da der ja nicht durch die MCC läuft und zusätzlich die Gerätefunktion rausrechnen, da die auch erst durch die IMS reinkommt. Alternativ: Gibt es reine MCC-Daten?
 ** Messungen unter home/ims gut sind die 6er/7er gemische, KK-Daten. Bei den Pseudos sieht man gut die Gerätefunktion
 ** Er hat mir zwei Paper-links geschickt und was zum Einlesen der Daten. Ein Programm, um die Gerätefunktion zu berechnen gibt es auch
 ** Jetzt erst mal rausfinden, was ich wirklich davon tun soll.
 
16.10.2014
 * Echte Daten: In den vorhandenen IMS-Messungen gucken. Nur wo bitte soll das drin stehen?
 * Für die halbe-peak-breiten-berechnung einfach eine spalte der Messung nehmen, was Dommi sagte, ist nicht so wichtig, da ich ja auch nur einen Peak sehen will und nicht das ganze Chromatogramm
 * fsolve macht nicht so ganz das, was ich gerne will, manchmal wird nur ein Schnittpunkt gefunden oder auch einer, der nicht da ist. Muss wohl an den start estimates liegen
 * Sollte jetzt die siebener-Gemische angucken und die Werte ermitteln
 * Größeres Projekt könnte sein, die Zusammenhänge zwischen Parametern und den Breiten zu ermitteln. Mir fehlen leider immer noch die echten Werte
 * Zeitskala sollte bis 600 gehen; vor 50s ist schlecht was zu erkennen; Peaks mit wenig Tailing sollten dabei 25-30s breit sein, krasses Tailing geht dabei schon mal übers halbe Bild
 
 
 30.10. 2014
 * Fragen: Wo krieg ich nun die echten Daten her? Ist das Peakbreiten-Plotting so ok?
 * Im Breitenplot: Parameter so raussuchen, dass eine gerade entsteht, hoffentlich passiert das mit einem bestimmten zusammenhang zwischen den dafür nötigen params. Dann im skew-plot gucken, ob da auch ein zusammenhang existiert
 * Was tue ich, wenn ich jetzt so eine gerade gefunden habe?
 * Gerade auch bei festen ps und variablem pm?
 * Spektrum plotten für "viele" ok
 * Jetzt endlich aus den echten Daten die Breitenverhältnisse raussuchen (dafür brauch ich aber schon nen ganzen morgen... mindestens...)
  ** Ideen dazu: 
  ** Im Wesentlichen eine Messungsklasse, die genau das hat, wie meine Sim
  ** Dazu: Einlesen einer einzelnen Messung. Hier stehe ich wieder mit nem Brett vor dem Kopf da: Muss ich das jetzt für nen ganzen Peak (sprich muss ich da mehrere Spalten aufaddieren) oder reicht tatsächlich eine Spalte? EIGENTLICH (denke ich zumindest) müsste ich das alles aufaddieren und den Kram, den Dommi erwähnt hat, rausrechnen. Dann kann man meinetwegen immer noch einen einzelnen Peak raussuchen und den alleine betrachten. Sollte ein Analyt nämlich in der IMS-Dimension sehr breit werden, sehe ich im MCC-Spektrum möglicherweise nicht, WIE hoch er wirklich war. Zumindest sollte ich das bei der Auswertung berücksichtigen, dass IMS-breite Peaks evtl nen viel höheren Wert haben, als ich sehe.
  ** Weiteres Problem: Reicht da die Annäherung als Gauss? Dazu: Plots angucken!
  ** Aus den Zeiten ebenfalls die plots erstellen bzw die breite berechnen
  ** Zum Vergleich: Tabelle anlegen und gucken, welche Params von mir da hin passen (bisher gehe ich ja eher den umgekehrten Weg, nur meine Sachen anzugucken)
 * Problem: Die ersten Peaks fangen erst bei 100 an. In echt geht das aber schon viel früher (da ist quasi sofort was da). Dafür müsste ich meine Skalen aber anpassen, zb um Faktor 10. Aber dann hab ich auch keine Peaks mehr bei > 60... Also mal wieder das bekannte Problem, dass ich die Dinger nicht genug getrennt krieg. Alternativ müsste ich krasse Params wählen (ps=0.1 und pm = 0.9, dadurch wären die aber keine Peaks mehr mit Breite, sondern alle quasi gleichzeitig da)
 * Bei d3: Bei einem plus, bei einem minus?
 
 06.11.2014
 * Noch mal nachrechnen, ob das mit den 2km/s so stimmt ok... stimmt nicht
 * Gucken, wann die ersten brauchbaren Peaks in den Spektren erscheinen... Wird da echt nur zwei Mal pro Sekunde gemessen?
 * Zeiteinheiten festlegen
 * Simulation mit pm = 1 machen, sodass irgendwas zwischen 10⁻⁴ und 2s raus kommt (ersteres müsste für die 2km/s sein, letzteres sind die ersten halbwegs brauchbaren Peaks) -> Korrektur auf irgendwas zwischen 0.1s und 2s
 * Simulationen dann erst mal (mit den gewählten Einheiten) für zwei Minuten (statt bisher 10, also 120s) laufen lassen und gucken, ob man da brauchbare Params findet; korrektur auf vier Minuten
 *"irgendwas" gab es, dass ich im Endbericht nachlesen könnte, weiß aber nicht mehr, was das war :( Vielleicht sollte ich den einfach abends noch mal durchgucken
 * Beim Spektrum plotten irgendwie einen Farbverlauf einfügen, damit man nachvollziehen kann, welche Farbe welcher Plot ist (joa)
 * Beim Spektrum die gesamtskala auf 0..240 festlegen. ok, zusätzlich die höhe auf 0..1 festgelegt, das muss aber evtl noch geändert werden 
 * Bekommt man vorne auch breitere Peaks hin?
 * Heatmap für die Breiten erstellen. ok, jetzt nur noch sinnvolle pkombis für die plots auswählen
 
13.11.2014
 * Expose fertig machen!!!
 * Aus den 6er/7er Gemischen die Breiten bei halber Höhe heraus finden
 ** Dazu: Mit Visual Now anzeigen lassen (brauche den Plot rechts, Bildschirm drehen ;))
 ** Muss nicht 100%ig genau sein
 * Diese Peaks simulieren (also passende Params finden) Versuche also, Kombinationen zu finden, die bestimmte Breite an bestimmter Zeit erzeugen

 * Peakfinder: 
  ** Starte mit beliebiger Param-Kombi bzw suche in den bisherigen Sims nach guten Annäherungen
  ** evtl. davon eine auswählen, mit der weiter gesucht wird -> User Input nötig
  ** Je nach Lage und Breite Params verändern
  ** Brauche dafür genauere Infos, wie die ps und pm die Shapes beeinflussen (Aufschreiben, wo genau ist der Zusammenhang)
  ** Alternativ: Wenn nah dran, einfach viel in der Umgebung suchen
  
 * Das alles löst nicht das Problem mit dem Tailing
 
20.11.2014
 * map, imap, processing angucken, evtl ist das sinnvoll für mich; joa
 * Habe das Gefühl, wenn ich manuell vier mal was starte, dass das wesentlich langsamer ist, als wenn ich nur drei laufen lasse. Das sollte ich evtl testen (gucke nach gesamt/einzelzeit für 3*4 oder 4*3 Simulationen). Dann würde sich das multiprocessing evtl auch anbieten, s. Done
 * Evtl lohnt es sich, noch mal die wpw-Sim auszupacken, die war (wenn ich es richtig in Erinnerung habe) viel schneller, wenn nur selten was passiert. Zumindest für Sims mit mehr Teilchen, damit ich ne schöne Ausgabe habe, die ich später verwenden kann, würde sich das evtl lohnen;
 * Auch interessant wären so Dinge wie: Ist es schneller, wenn die simulationsmethoden direkt im Programm stehen oder über die Simulationsklasse aufgerufen werden??
 * erstelle Plots, auf denen für bestimmten Zeitpunkt zu sehen ist, welche Params einen solchen Peaks erzeugen und welche jeweilige Breite damit erreicht wird (siehe Zettel)
 * Für diesen neuen Plot:
  ** Ausgehend von mehreren Kombinationen in der Nähe alles weiter eingrenzen (joa, ist momentan manuell machbar)
  ** Möchte ausdrücklich mehrere Kombinationen haben, daher evtl aus der anderen Richtung kommen und für feste ps oder pm (was ist sinnvoller) den jeweils anderen Parameter annhähern, bis ich gut genug die Zeit treffe
  ** Wie genau muss das eine Retentionszeit treffen? -> Ergebnisse, man erkennt ganz gut eine Gerade bei epsilon = 0.1
  ** Peakfinder automatisch annhähern lassen! hmm...
  ** Starte mit mehreren verschiedenen ps, für die passende pm gesucht werden. Es reicht ja, jeweils den ein klein wenig anzupassen und zu gucken, ob der Peak in die richtige Richtung wandert. Da die Breite ja egal ist, kann einfach der zweite Parameter optimiert werden, wenn entweder die Zeit erreicht ist, oder die Änderung zu gering -> Abbruch
  ** Es wäre doch sinnvoll, beide Params zu verändern (möglicherweise aber auch nicht gleichzeitig) da sonst mehrere mit gleichem ps (pm) und verschiedenem pm (ps) die Zeit beschreiben.
  ** Brauche, damit es präzise wird, Sims mit 10000 Teilchen. Dafür noch mal die wpw auspacken, da manchmal schneller
 * Aufschreiben, was bisher erreicht wurde, wo die Grenzen sind, was nicht geht etc. 
 * Es wäre schade, wenn das das einzige Ergebnis bliebe... (Aber das heißt, dass es immerhin schon ein Ergebnis ist)
 * Vorher erst mal Expose fertig machen, jetzt aber wirklich; Ich bin ja dran...
 * Code aufräumen, ordentlich dokumentieren und ne "finale" Version der 2-Param-Sim erstellen
 
27.11.2014
 * Literatur für's Expose raussuchen und einbinden
 * Auf Rückmeldung warten, wer genau den Zweitbetreuer macht
 
06.01.2015
 * Expose überarbeiten (joa, s.u.)
 * Tau-Leap Methode angucken (?, fällt doch raus)
 * Links (Mail vom 12.12) angucken (ok)
 
 * Im Expose: 
  ** Titel ändern, IMS weglassen
  ** Literatur einheitlich, (Journals groß, rest klein, auch wenn im Orig anders)
  ** Statt tau-leap: waiting time/wartezeit
  ** Andere Arbeiten erwähnen, die !nicht! das gleiche tun, wie ich (hplc/spreadsheet etc.) Dazu evtl genauer rausfinden, das hplc tut, paper gucken (Steht drin: "based on experimental measurements", also keine echte Simulation in unserem Sinne)
  ** Literatur im text vernünftig zitieren
  ** Halbe-Peakhöhen-Breite als Vergleichsmaß erwähnen, dazu schreiben, wie viele Datensätze zum Vergleich vorliegen
 * Sachen fürs Prüfungsamt raussuchen und hingehen (Do geht nicht; Alte Ausdrucke, wegen DVEW)
 
 * Zitieren: Wie krieg ich beim Buch das "Auflage" weg
 

15.01.2015
 * Numba
 * Expose überarbeiten
 * Prüfungsamt
 * Evtl schon mal Folien anfangen, Dinge aufschreiben
 * In der Bib: (Säulenbluten) Adsorptionseffekte verursachen Tailing
 * Stoffe wie amines, alcoholes, carboxyl etc prone to tailing wegen hydrogen bonding (Genauere Ursachen?)
 * Um Tailing festzustellen: Peakbreiten in 10% der Höhe messen. 
 * Für Halbwertsbreite evtl noch Basislinienhöhe abziehen? Damit müssten die gemessenen Breiten größer werden, da die Höhe abnimmt und Peaks auf der Hälfte breiter werden
 * Noch mal an Dommis Rechner -> hatte ich für die Höhen die Basislinie abgezogen? 
 * Was soll zum PAA ins expose? 
 

29.01.2015
 * Doch noch nen Satz mehr ins Expose zum PAA. Kurz erklären, was er tut und Entsprechungen für Zustände, Werte und Emissionen
 * Mosdi angucken, PAA damit basteln.
 * Da das Berechnen mittels PAA doch recht lange dauert, vielleicht wäre es sinnvoll, das Ganze in Teilprobleme zu zerlegen...?
 * Dazu müsste man in der stateValueStartDistribution was anderes angeben. Spontaner Gedanke dazu wäre es, dazu vorher x Iterationen zu machen, möglicherweise mit der doubling technik, bis zu in etwa der zeit, wo es interessant wird (oder x=länge) und dann noch mal als neue max-zeit die erwartete Breite des peaks anzugeben. Dann muss man zwar das ganze zum vergleichbaren plotten noch verschieben, aber das sollte hinkriegbar sein. Den Gedanken sollte ich in Ruhe und auf Papier noch mal überdenken, dazu am Besten noch mal mit 10 Iterationen oder so in der Sim angucken und vor allem überdenken, ob das mit der stateValueStartDistribution so passt.
 * Gibt es ne sinnvolle möglichkeit das zu zerlegen? die doubling-technik nützt mir wohl nix. Ob das Zerlegen was bringt, glaube ich nicht mehr, da es linear in den Schritten und values ist (ohne die doubling). Könnte aber doch was bringen, falls sonst die Arrays zu groß werden
 * gnuplot angucken und versuchen, da was aus java reinzupipen

 
05.02.2014
 * Expose: Ausdrücklich schreiben, dass zwischen Modellparametern und Peaks (mit Lage, Breite, Schiefe) hin und her gerechnet werden soll
 * PAA: Gucken, ob ich das (mit Julia) nachprogrammieren könnte und dann nicht mehr auf 2D double-arrays gearbeitet wird, sondern irgendein Interface möglich ist, was zwar mit 2Dd-a implementiert werden kann, aber nicht muss, um die nicht verwendeten Teile rauszuschmeißen. Ein Großteil ist ja noch nicht erreicht und daher null oder schon bis auf minimale Restw'keiten geleert.
 * Anfangen zu schreiben/Vortrag
 * Brauche Möglichkeit, die vom PAA berechneten Wartezeiten zu speichern. Da hier ja auch nie mehrere Durchläufe nötig sind (kommt bei gleicher Eingabe immer das gleiche raus) lohnt sich das. Sinnvoll wäre wahrscheinlich eine csv
 * paa-klasse anpassen, dass die parameter einstellbar und die größen anpassbar sind
 
 
11.02.2015
 * Vom PAA berechnete Daten exportieren; auf die Werte normalisieren (Einheiten)
 * Langfristig: PAA-Daten und Simulationen vergleichen / Unterschiede berechnen / Ab wie vielen Teilchen hinreichend genau? Existieren Differenzen?
 * Zu diesem Zweck wäre es evtl. günstig, die bisherigen Histogramme auch in Wahrscheinlichkeiten umzurechnen, die dann als einfacher Plot darstellbar sind. Oder anders herum, irgendwie die Wartezeitverteilung zu konkreten Daten umzuformen (was aber weniger Sinn machen würde, da dort Rundungfehler beim Umrechnen auf ganze Zahlen auftreten würden?)
  -> In Python: Bei plt.hist (bzw dahinter np.histogram) über normed/density wird das auf 1 normalisiert, sodass sich W'keiten ergeben
    >>> a -> array([2, 3, 3, 4, 4, 4, 5, 5, 6, 7]) # Minidatensatz
    >>> hist, bin_edges = np.histogram(a, bins = 6, density = True) # a: Daten; hist, bin_edges entspr. n, bins (patches) bei plt
    >>> hist -> array([ 0.12,  0.24,  0.36,  0.24,  0.12,  0.12])
    >>> bin_edges -> array([ 2., 2.83333333, 3.66666667, 4.5, 5.33333333, 6.16666667, 7.])
    >>> b = hist * np.diff(bin_edges) # Berechne Wkeitsvert
    >>> b -> array([ 0.1,  0.2,  0.3,  0.2,  0.1,  0.1])
    >>> plt.plot(b)
    >>> plt.show()
 * Dringt der Analyt in die stat ein oder bleibt er dran kleben? (-> Vortragsgraphik)
  ** Adsorptions -> Ablagerung an der Oberfläche durch van-der-waals-kräfte oder Wasserstoffbrückenbildung (stärker)
  ** Verteilungs -> Lösung in den Phasen
  
  
19.02.2015  
 * Mail an Rahnenführer (Termin Vortrag ab 02.04.)
 * Schreiben: Modell -> Wie beschreibe ich mein Modell formal. Am Besten erst mal auf Papier...
 
 
16.03.2015 
 * Mein Plan für die nächsten Wochen:
  ** PAA in Julia implementieren
  ** Aufschreiben:
   *** Grundlagen
   *** Modell
   *** Implementierung
   *** Stichpunkte zu Evaluation/Diskussion
  ** Implementierungen angucken und eine "Final"-Version erstellen, die gut kommentiert ist
  ** Drei-Parameter-Modell erstellen, implementieren (erst nach dem review der alten versionen)
 * Review:
  ** Nötige Dateien:
   *** IMS_Dommi/peak_width.py abh: ims_core.py
   *** Param_p/2-Param-Modell/peakfinder.py /2_param_v005.py (evtl. parallelv005?)
   *** Param_p/Wannpassiertwas/ ? (->simulation)
   *** Pythonkram/Plotkram/plotkram.py 
   *** Pythonkram/Simulationsklasse_2Param/simulation.py
  ** Aufruf von 2_param_v005 startet Simulationen, über Kommandozeilenparameter bestimmt, welche
  ** Zusätzlich neues Script, welches Plots ausgibt (Plottings?) und eines, das Berechnungen anstellt und diese dann ausgibt.
  ** Peakfinder kann 2_param_v005 aufrufen, mit pcombis
  ** Überlegung für die ganzen Plotsachen: Aufruf geschieht ja entweder from_file oder mit Daten. Problem: Dateien manchmal unsortiert, was für das Plotten doof ist. Erstelle also jeweils alles mit funcxy_from_file zusätzlich, welches die Daten extrahiert und funcxy aufruft
  ** peak_width fliegt raus; effektiv nur calculate_width (ehemals fpwahph) genutzt, das zieht um in die sim-Klasse. Plot-Dinge sollten entsprechend ins my_plottings umziehen  
 * Mal von nem anderen Rechner testen, was bisher so da ist  
 

26.03.2015
 * ist es besser array leer anzulegen und zu pushen oder vorher länge festzulegen und über indexzugriff zu setzen?
 * Alternatividee zu den sparse matrices: Einfach Liste speichern, da die Werte ja in einem zusammen hängenden Bereich sind. Jeweils den ersten Wert testen, ob er noch über einem Grenzwert ist, falls drunter, eine Index-Variable erhöhen und die erste Stelle löschen
 * Klären, ob allgemeiner PAA gewünscht ist, oder die spezifische Variante reicht
 * WaitingTimeForValue
 * Zeitanalyse: Am meisten Zeit scheinen push! und unshift! zu benötigen, keine Ahnung, wie ich das umgehen kann. Alternativ könnte ich doch mal eher den PAA aus mosdi nachprogrammieren, glaube aber kaum, dass das was bringt

09.04.2015
 * Bei den Peaks noch mal die Breiten überprüfen, dabei Basisrauschen beachten (dadurch werden die vielleicht schmaler, wenn Rauschen abgezogen werden muss) 
 * Screenshot / jpg-Export von den Visual Now - Ansichten
 * Welche Ergebnisse sollen in den Vortrag?
 * Noch mal einen Plot wie in 7a erstellen, aber mit je 10000 Teilchen.
 * In der simulation noch mal nachrechnen, welche Einheiten nun korrekt sind
 * Muss ganz dringend den PAA mit dem PAA überprüfen, welche Zeiten jetzt realistisch sind. Habe ein Faktor10 Problem -> Plotten
 
23.04.2015
 * Plots per Inkscape nachbearbeiten für Lesbarkeit
 * Markoff-Ketten erwähnen
 * Sven vorher Folien zeigen
 * Zahlen auch in den Plot zur Lesbarkeit trennen
 * Ausprobieren in python: r"p_s" oder so ähnlich. Noch mal Henning/Nina fragen
 * Cooles "Video", wie die Teilchen da durch wandern (zu mehreren Zeitpunkten als Bild ausgeben und zusammen schneiden)
 * Die neuen Modelle umsetzen, vor allem theoretische Überlegungen, zur Berechnung. Zustände nicht mehr einfach als true/false darstellbar
 * Gedanken zur Adsoptions-Sättigung machen, wie ist das einbaubar?
 * In VisualNow überprüfen, ob tatsächlich die sehr intensiven Peaks oben abgeschnitten sind
 * Gedanken machen, ob nur der Maximalpunkt, oder Intervall betrachtet werden soll
 * Baustellen sortieren
 * Weiter schreiben, besonders Dinge, die ich im Vortrag erwähnt habe