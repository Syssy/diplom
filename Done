 Kategorien: 
 * Gelesen
 * Getestet (Ausprobiert)
 * Programmiert
 * Geschrieben
 * Offen/Fragen
 * Sonstiges
 
 
seit 30.April 2014

* Gelesen: PG-Bericht quergelesen, ebenso PAA-Teil in der Diss von Tobias
* Gelesen: PAAs; Idee dazu: Zwei Zustände (weiter & hängen bzw stationär&mobil); Emission ?; Wert: zurückgelegte Strecke (wird nur in weiter erhöht) -> Verteilung berechnen, wann die Strecke zurückgelegt wurde (Waiting time for a value)
* Gelesen: Chromatographie, die Phasen dabei -> W'keiten zu wechseln sind jeweils recht hoch (?!) (-> Verlängert die Simulationszeit :( )
* Gelesen: Sorbtion: Wenn schon viele Teilchen haften, sind alle Plätze besetzt. -> Vielleicht eher nach Zeitschritten sim. und zählen, wie viele schon haften. Bzw. 
* Gelesen: qq-Plots: Zwei Verteilungen/Verteilung+Messwerte/zwei Messewerte gegeneinander plotten (Quantile davon); Ergibt sich eine Gerade, liegt die gleiche Verteilung zu Grunde. ist invariant gegen scal/loc, aber nicht für alle param. 
* Gefunden: HPLC-Simulator/retentionprediction: http://retentionprediction.org/hplc/howitworks.php; scheint eine statistische Vorhersage zu sein, keine Simulation. Darin: Einfach nur die Steps berechnen reicht nicht, man braucht noch eine Ausgleichskurve, die aus Testdaten gewonnen wurde
* Sonstiges: Zeitplan aufgestellt/Motivation
* Getestet: Einfacher qq-Plot. 
* Getestet: qq-Plot von der einfachen Simulation gegen inv. Gauß, aber das passt wohl nicht. Normalvert scheint aber super zu passen
* Einfluss haben: Adsorption, Verteilung, Ionenaustausch, Ausschluss(?), Affinität, Temperatur, Druck, Länge, Polarität, Geschwindigkeit, Teilchengröße, Porösität (?), Diffusionskoeffizient d. stat. Phase, 

Seit 20. Mai 2014
* 1-Parameter-Modell 1a und 1b getestet: 
 ** 1a) Es kommen annähernd Gaußkurven raus, mit Mittelwert um die doppelte Länge. Parameter beeinflusst da nur die Varianz (Parameter klein, Vari groß) -> Stimmt nicht, hohe WKeiten! s.u.
 ** 1b) Es kommen annähernd Gaußkurven raus. Je größer der Parameter desto schmaler und früher die Kurve
 ** Startzeiteinfluss: Keine Gaußkurven mehr, aber auch keine Invgauß.
 
 Seit 4. Juni 2014
 * Zum Generieren der ZZV: Habe das Gefühl, eher das Zugreifen dauert lange, nicht das Generieren, zumal die np-Variante nicht schneller ist (im Generieren schon, Zugriff nicht). Durchlaufe ich meine Zufalls-array (statt jeweils aufzurufen) wird es schneller, dann müsste ich aber mit breaks arbeiten...? -> Jeweils direkt generieren scheint immer noch schneller
 * Bei Länge 10000 und p=0.999 gibt es eine schöne Kurve. Kann die aber leider kaum verschieben, da bei kleinerem p wieder eher normalverteilung, bei größerem reicht die Strecke nicht, da gibt es zu viele die komplett durch kommen ohne hängen bleiben (im hist: erst ein großes bin, dann viele kleine; qq passt aber irgendwie?)
 
 
 Seit 11. Juni 2014
 * Erzeuge nun np-array mit ZZ (so viele wie Teilchen). Daraus zwei arrays für je einen parameter (ps, pm) und dann mit binären Ops neues zustandsarray (true -> mobil, false -> stationär). Das ganze auf den die Orte draufaddieren (wenn mobil, dann ein platz weiter vorne). 
 * Abbruchbedingung jetzt auch ohne Schleifen
 * Plotkram: Erzeuge jetzt je Sim ein Fenster mit separatem Histogramm, und beiden qq-Plots. Zusätzlich möglich ein gesamtspektrum
 
 
 Seit 18. Juni 2014
 * Sinnvolle Werte für Modell 1a liegen bei Länge 100000 und 1000 (10000) Teilchen zwischen 0.99978 und 0.99995 Zeit dafür: Je 6-7s (30-40s) (plus Statistiken erstellen, das dauert deutlich länger je mehr Teilchen) Allerdings alle Peaks mit ähnlichem Mittelwert (ca 200000)
 * Variiere Abstand zw ps und pm um Peaks zu verschieben: 
  ** ps < pm: Irgendwie nicht hübsch :(
  ** ps > pm: Irgendwie noch weniger hübsch :((
  ** Bezog sich beides auf jeweils gleiche Abstände -> Unterschiedliche Abstände plus ps<>pm
 * Teste versch. Abstände durch (Varianzveränderung?):
  ** Bei konst ps und größerem pm: Je größer der Abstand, desto kleiner Varianz und desto weiter vorne der Peak
  ** Bei konst ps und kleinerem pm: Je größer der Abstand, desto größer Varianz und desto weiter hinten der Peak
  ** Reicht aber nicht aus, um Peaks zu trennen
  ** Mobil kleiner als stationär: Peaks werden breiter
  ** Diff größer, aber Wert kleiner (der beiden Params) -> Peak nach hinten; Diff 0 und Wert klein auch, dann aber fast gaußkurve!
 * Legende für die Spektren
 * Statisik-Variablen werden direkt ein mal berechnet (mu, mean etc) und mit in der Sim gespeichert
 * Direkter Plot-Aufruf ohne speichern der Daten möglich
 
 Seit 02.07.2014
 * Sim läuft jetzt an der Uni ACHTUNG: Die .p-Dateien speichern leider immer alle bisherigen Sims (das Array) ab, nicht nur je eine Sim -> nur die gesamtdingens nutzen -> Korrigiert
 
 Seit dem 31.07.2014
 * Simulation während der Ferien liefert seltsame (identische) Ergebnisse bzgl skew/kurt. Keine Ahnung warum
 * Liegt wohl an der Scipy-Version, an der Uni ist eine alte, da passt das stats fit invgauss nicht
 * Momente werden jetzt direkt berechnet, ohne Invgaußparameter (sind ja hier ein Umweg)
 
 Seit dem 05.08.2014
 * Plot mit 4 Heats klappt wahrscheinlich, wenn keine Lücken (Sortierung haut das noch durcheinander) Es müssen quadratisch viele Sim vorliegen. 
 * Update: Ja, es klappt
 * Akuteller Status:
  ** Sim laufen
  ** 4 einzelne Heatmaps für jeweils die Ecken gehen, 
  ** Für die 10 000 er Variante gibt es einen Plot und für die 100 000 er auch, aber leider noch mit falschen Parametern (nicht nah genug in den Ecken, trotzdem sieht man schon was)
  ** Interessant ist vor allem die Ecke, wo beide Params groß sind, die laaangen Sims können dafür weggelassen werden, pm groß und ps klein auch noch schief
  
  
Seit dem 14.08.2014
* Sim laufen. Erkenntnis: Je höher pm, desto schiefer. Leider erst später dran gedacht: Das sind dann keine schönen Kurven mehr, sondern die vorne abgeschnittenen (Wo auch der qq-Plot Mitst ist). Die daraus mit scipy.stats.fit berechneten Parameter ergeben aber wieder hübsche Kurven, die zumindest derjenigen ähnlich sieht, die ich bekomme, wenn ich Dommis Beispielkurve plotte und dabei nur etwas den Offset verändere (2ter param bei scipy). Vom Gefühl her entspricht das aber nicht der Kurve in der Heatmap von Dommi. Die sieht irgendwie symmetrischer aus. 
* Außerdem getestet: Über den gesamten Parameterraum Sim laufen lassen. Gibt auf den ersten Blick keine weiteren interessanten Stellen
* Weiteres Problem: Die Kurven landen alle mehr oder weniger an der gleichen Stelle. Also kaum möglich, ein "Spektrum" mit mehreren Peaks zu bekommen. Es scheint, dass daher die zwei Parameter nicht ausreichen und das Modell erweitert werden muss.
 ** Ideen dazu: 
 ** Geschwindigkeit einführen, vel könnte von vorneherein unterschiedlich sein (Begründung? Größe der Teilchen, damit würde sich das Problem sicher lösen lassen, sit nur die Frage der Sinnhaftigkeit)
 ** Geschwindigkeitsveränderung nach Phasenwechsel/Wahrscheinlichkeitsveränderung je nach Geschwindigkeit. Hintergrund: In der Mitte der Säule kaum Kontakt mit sP, gutes Durchströmen möglich. Am Rand öfter WW, geringere Geschwindigkeit, da auch Richtung eher mal kreuz und quer. Also nach Hängenbleiben ist die vel geringer und dadurch auch die Wkeit höher, wieder hängen zu bleiben. Befürchtung: Dadurch wird das Tailing noch länger, aber die Anzahl der Teilchen, die ohne ww durchkommen noch höher. Bräuchte also Möglichkeit, dafür zu sorgen, dass viele wenigstens ein mal hängen bleiben
 ** Adsorptionseffekte? Keine Ahnung, wie das zu realisieren wäre, zumal ich auch die Simulationsgeschwindigkeit im Auge behalten muss
 
* Ergebnisse Profiling
 ** Vor allem bei kurzen Säulenlängen braucht das fit verhältnismäßig viel Zeit, die anderen berechnungen gehen sogar
 ** Am meisten Zeit frisst random
 ** Auch beim Profiling der neuen wpw-Sim nix, was mir hift
 
* Einfach nur Geschw verändern bringts nicht. Bei 10facher vel ist auch der "peak" 10-mal so lang/breit. Ich muss also per Parameter bei höherer vel die peaks schmaler machen, damit das klappt. Leider sind die echt schön schmalen Peaks nicht mehr invgaussig sondern normalverteilt.
* Habe Test mit variabler pm/ps: Damit gehen die Wkeiten noch näher an eins, bleiben aber schief, bzw. sind vorne nicht so abgeschnitten, da Wkeiten mind. ein mal hängen zu bleiben, stark erhöht.
 
* Auswertung des Files von Dommi:
 ** So ganz glücklich bin ich nicht damit, es sieht erst mal kaum schief aus. (Siehe snapshot 28 TODO im visualize ordner). Evtl muss ich noch mal mit den berechneten Intensitäten was testen und nicht nur mit den Integerwerten aus der Messung. 
 ** "Leider" sieht der qq-Plot ganz gut aus, aber da geht der hintere Teil sogar eher hoch, als runter, so wie bei mir immer. Das kann aber auch allgemein am Rauschen liegen ?!
 ** Die von Dommi angegebenen Parameter sehen aber ganz anders aus ... *ratlos* Vielleicht auch hier noch mal mit den Intensitäten was anfangen?
 ** Die Signalwerte sind ganz komisch. Alle etwa 0 und sowohl drunter und drüber. Der Rip ist am nächsten bei 0 (klar bei 1/zahl)... Tja, oder mit invertieren ist VZ-Wechsel gemeint. Dann kommt ne ganz hübsche Kurve raus... Aber auch die sieht nicht so ganz invgaussig aus.
 ** Insgesamt: Keine Ahnung, wie es hier weiter geht. Irgendwie hab ich das Gefühl, irgendwo einen doofen Fehler gemacht zu haben, den ich aber nicht finde.
 
* Die Auswürfeln-wann-wieder-was-passiert-Sim ist begonnen. Es läuft erst mal in einer Grundversion, wo noch die Parameter eingebaut werden müssen, noch nicht auf Geschwindigkeit geachtet wurde. Erinnert mich irgendwie an die phys. Sim von damals, da haben sich auch die Teilchen selbst aus den Listen gelöscht etc. 
* Parameter sind drin. Das auswürfeln entspricht einer geom. Verteilung (Anzahl Versuche, bis Bernoulli-Experiment klappt, Bernoulli, weil ich ja genau zwei mögliche Ausgänge habe und die jeweils unabhängig sind) Ich hoffe, das ist richtig so. Zeitlich ist das ein Unterschied zur bisherigen Sim, je nach Anzahl, Länge und Parameterwahl bin ich schneller oder langsamer. Ergebnisse sehen gleich aus (zum glück)

* Expose ist mittlerweile 1.5 Seiten lang. Naja...

15.09.2014
* Versuche, den neuen Ansatz zu verwirklichen. Params jetzt als vel und gamma bezeichnet
* Neue Ordnerstruktur, nach den beiden Ansätzen sortiert, dazu einige Kommentare geschrieben
* Da das wpw-vel-gamma irgendwie seltsam war noch mal mit der ersten simulationsart probiert. irgendwie schießt grad der pvektor/pneu quer...
* Sieht jetzt besser aus. 
 ** Speichere wieder die Sim ab, damit es schneller geht
 ** Versuche jetzt mit den aktuell vier(!) Params zu spielen und rauszufinden, was davon interessant ist
* Verdammter MIST!!!!!!! Jetzt ist irgendwas passiert und die Sim werden anders als vorher... Dabei kann ich mich gar nicht erinnern, da was in der simulate() geändert zu haben :(

29.9.2014
* Off-Topic: Statt der prints gibt es jetzt an einigen Stellen logging-Infos. Ist praktischer
* Immerhin, mit der v002 bekomme ich jetzt die Kurven aus der 1a)-sim wieder hin. Jetzt kann ich a) durch den zweiten Param die Form wieder ändern (später, bzw. tue ich das nicht indirekt auch durch b siehe-> ??) und b) durch die Geschwindigkeitsveränderung die Kurven verschieben (jetzt...!)
* Zeiteinsparung durch Teil2 in der Simulationschleife, ich teste jetzt erst mal nur, ob was durch ist und wenn die ersten da sind, geht es in Teil3, wo dann regelmäßig getestet und verkürzt wird. Haha, weitere Einsparung: Es wird jetzt immer auf das any getestet und nur wenn was zu tun ist, verkürzt. Dadurch entsteht dann auch kein dadurch verursachter Pömpel mehr vorne.
* Habe Rauschen hinzugefügt, einfach um zu gucken, wie das wirkt. 
* Lasse jetzt viele Sim mit verschiedenen variablen und festen Params laufen, um zu gucken, welche festen Params sinnvoll sind.
* Einflüsse verschiedener Parameter:
 ** Bei hoher W'keit wieder zu lösen (0.1 statt 0.001) entsteht starkes Fronting bei kleinen gamma-Werten (bleibt zu klären, warum?) 
 ** hohes ps (0.1): 
  *** insgesamt kürzere Zeiten
  *** ps beeinfluss relativen Abstand der Peaks, allerdings nicht gleichmäßig, die vorne rutschen zusammen, die hinten nähern sich an
  *** Fronting zu beobachten bei kleinem gamma (0.001), sonst nicht (mit bloßem Auge)
  *** Peaks hinten bleiben in der Höhe (relativ zueinander) stabil, vorne werden sie bei hohem ps flacher
  *** Ähnlich für die Breite, jedoch nimmt bei kleinem gamma auch die Varianz stärker zu (mit dem Fronting)
  
 ** Unter Bilder, figure1* findet sich das, was ich zu einem interessanten Phänomen bzgl der Geschwindigkeit gefunden habe
* Die Wahl der festen Parameter hat entscheidenden Einfluss darauf, welche variablen Parameter sinnvolle Dinge ergeben. -> Todo 
 
 
10.10.2014
* Off-Topic: git repo auf github angelegt und befüllt. Alles Alte ge-targz-et. Wurde aber auch Zeit
* In der alten 2-Param-Basis-Version gibt es ja noch gar nicht das Testen auf vorhandene Sims etc... Na klasse
* Versuche, Zeitskala anzupassen, mit der tollen Erkenntnis, dass meine "peaks" viel, viel, viel zu breit sind... 
 
* halfwidth-Berechnung ist völliger Bullshit, habe da jetzt einen ganzen Morgen rumprobiert und noch nix geschafft. Ich bin da grad zu blöde zu
* Sieht jetzt besser aus. (siehe peak_width.py)
* Die start-estimates hab ich jetzt mal auf loc+-scale festgelegt, das sollte zumindest für normalverteilungen einigermaßen passen

* Daten: To realize an effective pre-separation of the rather complex mixtures occurring in exhaled air, a 17 cm long weak polar multi-capillary column (MCC, Sibertech, LTD, Novosibirsk, Russia) made by combining approximately 1000 capillaries (see figure 2) with an inner diameter of 40 μm and a film thickness of 0.2 μm was coupled to the 63 Ni-IMS. The total column diameter of 3 mm allows operation with a carrier gas flow up to 150 mL min−1, which is the optimum flow rate for IMS. (JIB2009)

* in der halfwidth gibt es jetzt plot_relations. Damit werden die zuvor im fpwahph berechneten breiten gegen die loc-parameter der geschätzten Gauß-verteilung geplottet. Zusätzlich plotte ich die Skewness
 
 
02.11.2014
* Versuche jetzt, abhängige Params zu verwenden. Damit bekomme ich auch tatsächlich manchmal geraden im breitenplot, aber nicht immer. Leider auch nicht in den Parameterbereichen, die ich gerne hätte (damit Schiefe entsteht)
* Geraden entstehen auch bei festen pm und variablem ps (umgekehrt?) Aber nur in bestimmten Bereichen. Woanders zwar auch, aber zum einen nicht so schön (und hauptsächlich, wenn einer der beiden Params fast gleich bleibt) und sie werden deutlich steiler. Den Zusammenhang, um eine fast gerade hinzubekommen, habe ich noch nicht :(
* Carrier gas flow: 150 ml/min, wahrscheinlich auch mit 17 cm. Das aber noch /1000 wegen 1000 capillaries? und auf die 40μm inner diameter umrechnen. dann hätte man evtl die Geschwindigkeit der teilchen
* Code mal wieder umstrukturiert, argparse zur auswahl der pkombis eingebaut

 
07.11.2014
 * Geschwindigkeit ist bei ca 2m/s (in der Besprechung haben wir das gesamte Volumen nur durch eine Röhre statt 1000 geschickt) 
 * "Nebenbei" während die Sim liefen, code like a pythonist und pep style guide gelesen und Code etwas angepasst
 * Die Ergebnisse sehen naja aus. Zwar bekomme ich über die ganze Zeitskala Peaks, jedoch erscheinen mir diese zu breit und flach. Vielleicht täuscht das aber auch, weil die ersten extremst schmal und hoch sind
 * Habe einen recht schönen, nicht-linearen Zusammenhang gefunden (konst ps bei steigendem pm gibt schöne Kurve), und das halt für viele ps übereinander (bildchen+beschreibung)
 * Interessant dabei ist, dass für manche ps die Kurve oben einen Knick zu haben scheint. Scheint aber nur so, das verschwindet bei einer Sim mit 1000 Teilchen
 
13.11.2014
 * Erkenntnis: Höhere Peaks weiter hinten können tatsächlich von größerer Anzahl Teilchen kommen. Relevant ist daher die Breite auf halber Höhe, das ist davon (fast) nicht beeinflusst
 * Habe zwei 7er-Gemische und zwei 6er angeguckt und jeweils die Retentionszeit beim Maximum, das Maximum sowie die linke und rechte Breite auf halber Maximalhöhe (also den Abstand zum Maximum) rausgeschrieben.
 * Die Gesamtbreiten variieren zwischen drei bis 20+
 * Dabei festgestellt, dass doch oft Tailing auftritt 
 * Ansatz für Peakfinder, momentan werden aus allen vorhandenen Sims diejenigen rausgesucht, die (user-spezifizierte) bestimmte Bedingungen erfüllen. Davon darf man sich dann einen aussuchen und angeben, wie dessen Parameter verändert werden sollen
 
20.11.2014
 * Zeitmessungen: Es ist wesentlich schneller, nur drei pythons zu starten!
 * Habe (auf kleinen Zettelchen) für bestimmte Zeiten mögliche Paramkombis aufgeschrieben. Die Plots dazu sehen schon ganz gut aus (eine Gerade, so wie erwartet), es klappt auch, die Breite als Punktgröße zu nehmen. 
 * Um besser als 0.1 dran zu kommen, brauche ich die Sim mit 10000 Teilchen
 * Die Simulationsklasse hat jetzt beide Simulationsarten drin, die by_event (vormals wpw) ist in den aktuell genutzen Fällen deutlich schneller
 
06.01.2015
 * Habe letztes Jahr erste Version des Expose abgegeben und kann jetzt überarbeiten
 * Spreadsheet-Geschichte: Die haben als Eingabe diverse (Gauß-)Kurven und simulieren damit, indem sie diese übereinander legen. Zusätzlich kommt das glaub ich noch was mit Massenspektrometrie rein, da die Einzelmassen der Komponenten betrachten. Also nix für uns
 * GC-Simulator: 
  **Code nicht gefunden
  ** versuche mich, durch den (vom gleichen Menschen gemachten) HPLC-Sim zu arbeiten. Da kommt als dRetentionTime ein double raus, ich denke, daraus berechnen die dann die passende Kurve. Und wenn man sich im isocratic (also nicht gradient) mode befindet, ist die Berechnung auch extrem kurz. Glaube nicht, dass das nutzbar ist. 
  ** ebenfalls von der Arbeitsgruppe: retentionprediction, aber dafür braucht man eigene Daten zum Vergleich (wird wohl ausgehend von bekannten Werten und Messungen vorhergesagt, wie's am eigenen Gerät aussehen sollte)
 * Nächstes Treffen: Mittwnoch, 10 Uhr Gruppe, ab 11 Expose, dann Donnerstag wie üblich
 
15.01.2015
 * Mittwoch nicht vergessen
 * Recherche zu Tailing: Ursachen sind Adsorptionseffekte & technische Dinge wie totvolumen, sowie einige Stoffe die halt einfach tailen 
 * Formulierung als PAA angefangen. Dazu Paper gelesen (zum x-ten Mal)
 
 
22.01.2015 
  ** Das mit den W'-Keiten = 1 macht dabei keinen Sinn. Es geht ja grad darum, jeweils mit der gewissen Wkeit in jedem Zustand zu sein. Bin nur grad unsicher, wie ich neben dem Zustand, der ja eig. egal ist, auch den Ort rauskriege. Ist der aufh mit Wkeit?
  ** Evtl Modellierung der Ortsschritte. Dann wäre die Emission die Zeit, die ich für einen Ortschritt brauche. Ich könnte dann die Verteilung der Zeit nach x Ortsschritten berechnen. Klingt erst mal sinnvoller. Benötigt aber zig Zustände.
  ** Nein, nur zwei Zustände. trotzdem ist emission die Zeit für den nächsten Ortsschritt. Gesucht ist dann Verteilung der Zeit nach x Ortsschritten.
  ** Und noch ne Idee: Nur ein Zustand. Jede Transition ist ja ein Schritt, da hätte ich ja sowohl beim wechsel von m->s als auch s->m einen Schritt zurück gelegt, was ich ja nicht will. Daher gibt es eine Selbsttransition mit pm und Emission von 1 für einen Orts- und Zeitschritt. Und eine mit 1-pm. Das ist ein Wechsel ins stationäre und zurück mit nur einem Ortsschritt. Emission berechnet sich dabei wie gehabt aus ps. Das wäre irgendwie eine Kombination der beiden bisherigen Simulationsarten.
  ** Um das erweiterbar zu machen, könnte man auch mit halben Schritten arbeiten. 
  ** Verdammt. Emissionen sind zustandsgebunden. Müsste man also doch mal mit halben Schritten probieren...
  ** Ein einfaches Modell wäre nutzbar, wenn das mit den Waiting times für die PAAs so wäre, wie ich das gedacht hatte. Aber da muss man wohl für jede mögliche Waiting-Time was berechnen, um die Verteilung zu erhalten. Also doch eher das Ortsschritte-Modell nehmen und da direkt die Verteilung nach x OSchritten nehmen.
* Literatursuche: Gar nicht so einfach, das mit dem Tailing. Habe jetzt was von 1955, wo es um ein stochastisches Modell für die chroma geht. Wäre vielleicht mal interessant. Darüber bin ich auf ein ganz neues Paper gestoßen. In dem geht es auch um theoretische Ursachen für's Tailing: kinetische Effekte und Sorption. Sollte ich zitieren und fertig...  
  
  
28.01.2015
 * Der PAA klappt doch mit der ursprünglichen Modellierung, weil die Waiting-Time sowieso schrittweise für alle Zeiten bis n berechnet würde. Muss dann nur gucken, dass ich bei der Mosdi-implementierung eine sinnvolle maxzeit angebe.
 * PAA-Berechnungen laufen, brauchen aber lange. 
 * Die Doubling-Technique ist wahrscheinlich für mich nicht sinnvoll einsetzbar. Ist nämlich kubisch in der Größe des value-sets und damit wahrscheinlich langsamer, als die normale step-by-step geschichte. 

->boehmer@citrin:~/workspace$ javac -classpath /home/boehmer/workspace/mosdi-1.3/mosdi-1.3.jar  /home/boehmer/workspace/PAA/src/myPAA.java
compiliert!


04.02.2015
boehmer@citrin:~/workspace/PAA/src$ javac -classpath /home/boehmer/workspace/mosdi-1.3/mosdi-1.3.jar myPAA.java 
boehmer@citrin:~/workspace/PAA/src$ java -classpath .:/home/boehmer/workspace/mosdi-1.3/mosdi-1.3.jar myPAA 
läuft
 * Der PAA läuft. 
 * Graphische Ausgabe mit Java läuft jetzt auch irgendwie. Habe die Javaplot-Library doch verworfen, da ich das nicht so ganz hingekriegt habe. Könnte aber auch daran liegen, dass die Ausgabe des PAA (also die Wartezeiten) nicht direkt als Histogramm anzeigbar sind. 
 * Rahmen für den Vortrag angefangen

11.02.2015
 * Mir ist so ein bisschen das "Große Ganze" klar geworden. Es geht im Endeffekt um die Vorhersage von Peaks anhand von Stoffparametern. Im Informatik-Teil geht es darum, einen Zusammenhang zwischen den Simulationsparametern und den Peakparametern zu finden. Im zweiten Schritt können sich dann irgendwelche Chemiker oder Biologen Gedanken machen, ob diese Simulationsparameter sich aus Stoffeigenschaften ableiten lassen. Naja, ob das einfacher ist, als direkt aus den Peaks, wage ich noch anzuzweifeln, zumal der Zusammenhang relativ direkt erscheint (also was ps und pm mit den peaks tun) Aber vielleicht kann man das ja irgendwann weiter denken. 
 Hmm, so viel schlauer bin ich doch nicht.
 * Folien angefangen, v.a. Tikz-Bilder
 
 
19.02.2015 
 * Terminklärung für Einführungsvortrag läuft.
 * Ein bisschen Julia angeguckt

 
16.03.2015
 * Vortrag am 23.4.

26.03.2015
 * Angefangen PAA in Julia zu implementieren
 * Läuft auch und kommen Gaußkurven raus. Allerdings nur eine sehr spezifische Variante für genau diesen PAA. Bisher existiert auch nur die "computeStateValueDistribution", eine "WaitingTimeForValue" fehlt noch. Jetzt nicht mehr
 * Es lohnt sich Float32 zu verwenden (ist schneller als Float64)
 
09.04.2015 
 * simulation_2p.py in der PreFinalenProgrammierung ist bis auf zwei Todos fertig
 * Die Vortragsfolien entwickeln sich weiter
 
23.04.2015
 * Vortrag gehalten
 * Noch mal schrittweise meine beiden Sim-Arten durchgegangen. 
 * Mein Faktor10-Problem war ein Python2-Problem, welches sich mit from __future__ import division beheben lies und trat wohl auch nie mit Python3 auf.
 
30.04.2015
 * Die Sim in der _2p sollten jetzt gleiche Ergebnisse liefern
 * 3-states angefangen und die by-event läuft auch. vergleich (mit genau einer paramkombi) mit der 2p erfolgreich, ist bei 1000 Teilchen sogar schneller, aber leider etwa linear, während die alte sim da deutlich besser ist. 
 * Den zweiten und dritten Zustand tauschen geht auch und wenn ich nur die beiden stat mit rein nehme, kommen die Teilchen nicht vom Fleck, verteilen sich aber auf die beiden Zustände, so wie gewünscht
 * Beispielzeiten für die verschiedenen Sim: ps=0.9994, pm=0.7, n=5000(1000), l=200000, Schrittweite = 100
  ** 2p, timestep: 86s (32s)
  ** 2p, event: 169s (86s)
  ** 3s, timestep: 254s (100s)
  ** 3s, event: 222s (55s)
 * Neue Modelle: 
  ** 3a) Keine Übergänge zwischen den Zuständen:
   *** Wenn die W'keit, in beide reinzugehen, ähnlich ist, aber sehr unterschiedliche W'keiten habe, entsteht zumindest kein Tailing
   *** Kann ein Tailing erzeugen, ähnlich, wie bei der 2p, da gab es ja auch die ganz bestimmte param-kombi. ich hoffe nun, dass ich mit hilfe des anderen stat zustands das ganze verschieben kann. solange die w'keit in den tailingzustand überzugehen, bleibt, müsste das tailing sichtbar bleiben. Bisher gelingt das zu verschiedenen Zeitpunkten 
 
07.05.2015
 * Experimentierphase hat begonnen
 * 3a liefert auf jeden Fall brauchbare Peaks (zumindest auf den ersten Blick) Es sind auch eher schmale, schiefe dabei. 3b) sieht erst mal schlechter aus.
 * my_plottings_2p überarbeitet und getestet und kommentiert.
 
21.05.2015
 * Erste Intensitätsplot zur Rauschwertbestimmung fertig. Passt auch, wenn nur ein einzelner Peak im Chromatogramm. 
 * Berechnung der Schiefe der Referenzdaten läuft. 
 * Treffen mit Rahnenführer: IQR als Maß fuer die Breite, sowie demnächst robustes Maß für Schiefe

28.05.2015
 * Simuliere für l=170000 um herauszufinden, ob evtl bei kürzerer Säule die knapp verfehlten Peakbreiten erreicht werden können (Dabei Fehler entdeckt s.u.)
 * 3s: Umbenennung der Sim 
 * Teilweise Umstellung der Breite auf IQR
 * Fehler entdeckt in der Normalisierung der arrival_counter daten. Bisher wurde unabhängig von der Länge auf eine Totzeit (Zeit für Driftgas) von 0.1 normalisiert, was allerdings Quatsch ist, beachtet man verschiedene Säulenlängen. Das wurde behoben (2p/3s). Das ganze noch mal korrigiert, denn ich hatte wohl noch mal Mist gebaut. Das (gewünschte) Verhalten: Doppelte Säulenlänge bei doppelter Schrittgröße liefert gleiches Ergebnis. Ebenso ist die Abbruchzeit unabhängig von der Länge oder Schrittgröße, sondern deren Zahlenwert soll einstellbar sein
 * Tests mit Invalid-Flag fuer abgebrochene Sims
 * PAA: 2p läuft, Julia liefert gleiche Ergebnisse wie mosdi. Im Wesentlichen sind die Ergebnisse auch mit den Simulationen identisch. Erst dachte ich, das dieser hohe Anfangspeak bei 0.999/0.999 l=1000 anders ist, als bei den Simulationen, aber durch die Kumulation fällt das da nur nicht auf. Das sollte aber kein Problem darstellen, da bei den realen Messungen ja auch nur "gelegentlich" gemessen wird.
 * PAA 3s sieht ähnlich gut aus. Die Ergebnisse von Julia, mosdi und den Simulationen sehen gleich aus. 
 * PAA: Zeitlich ist Julia echt am schnellsten, je nach Parameterwahl macht das einen krassen Unterschied
 * Habe weitere interessante Phänomene bei den PAA3s gefunden, aber nur, weil da halt bis zum Ende simuliert wird und nicht abgebrochen. Ist wahrscheinlich gar nicht relevant
 * PAA in Julia in seriensimulation
 * Verschiedene Versuche, das noch zu beschleunigen, mit mäßigem Erfolg
 
18.06.2015
 * Basisversion der pd-Tabelle steht
 * Robustes schiefemaß ist der Interquantilskoeffizient (Yale-Bowley bzw Yale-Kendall)
 * Bei IQK ist Wert > 0.02 schon leicht erkennbare Schiefe. Bei meinen Peaks aber meist nur schwaches Tailing auf niedrigem Niveau. Bei Wert > 0.4 meist extrem schmale Peaks am Spektrumsbeginn oder tatsächlich sehr ausgeprägtes, schönes Tailing
 * 0 am Ende scheinen gar nicht vorzukommen, sind nur extrem kleine Werte bei sehr langem Tailing
 * Peaks mit max bei 0.9999 etc und p50 woanders sind welche mit hohem Anfangsausschlag (genau ein zeitpunkt) und nachfolgendem Peak
 
25.06.2015
 * Basisversion des Plots steht: Plotte für best Zeitpunkt an den Achsen die IQR und IQK und die Punkte jeweils für einen Peak. Beschriftung mit Params
 * Erstelle jeweils Tabelle für alle Peaks mit gewünschten Eigenschaften. Darin: Die Params und die Pd
 * Mich wieder in die Referenzdatenauswertung eingedacht
 
09.07.2015
 * Auch wenn jetzt "überflüssig": Referenzdaten ausgewertet, Tabelle mit den Peakdaten erstellt und Breite/Schiefe berechnet
 * Benenne sims um, damit nur noch die betrachteten 4 Params im namen vorkommen
 * Fehler in der Peakdatenberechnung entdeckt und behoben (maximum wurde falsch berechnet, wenn offset vorhanden war, da dieser zwei mal durch 10000 geteilt wurde), ebenso fehlte der offset bei den Quartilen, das hatte aber keine weiteren Auswirkungen, da die Abstände ja gleich blieben
 * Durch die Neuberechnung habe ich jetzt auch Peaks an einigen Zeitpunkten, wo ich vorher vergeblich gesucht habe *seufz*
 * Fehler in der offsetberechnung bei Julia entdeckt: Es wurde nicht nur zu Beginn der Sim, sondern auch am Ende 0 reingeschrieben, die dann in der offset-variante natürlich vorne mit drauf addiert wurden. In der Konsequenz heißt das, dass alle mit offset neu simuliert werden müssen.
 * Die betreffenden wurden umbenannt und können neu simuliert werden. Leider sind das 150 GB
 * Etwas geschrieben 
 
 * faszinierend1 bleibt auch nach neusimulation, ebenso faszinierend2. Der Fehler in kann_nicht_sein ist jedoch weg. In fehler_ruecklaeufiger_zeitpunkt springt leider die 0.999999 immer noch. Das verschwindet, wenn ich statt der Mediane wieder die argmax betrachte
 -> Findet nur in nicht relevantem Bereich statt, daher ignorieren
 * Mit Laufzeitvergleichstests auf dem alten Laptop begonnen
 
 
 
 
 
 
 
 
 
 
 